{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#referring to detecting_MNIST_examples_Crafted_By_L2_Attack.ipynb\n",
    "nn_robust_attack_root = '~/nn_robust_attacks/'\n",
    "home_root = '~/'\n",
    "import sys\n",
    "sys.path.insert(0,home_root)\n",
    "sys.path.insert(0,nn_robust_attack_root) \n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modified_setup_inception import ImageNet, InceptionModel\n",
    "from li_attack import CarliniLi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generate_data2(data, samples, start=0):\n",
    "    inputs = []\n",
    "    sources = []\n",
    "    targets = []\n",
    "    for i in range(samples):\n",
    "        inputs.append(data.zebraData[start+i])\n",
    "        tempLabel = np.zeros_like(data.zebraLabel[i])\n",
    "        tempIndex = data.zebraLabel[i].argmax()\n",
    "        tempLabel[(tempIndex+100) % 1000] = 1\n",
    "        targets.append((tempLabel))\n",
    "        sources.append(tempIndex)\n",
    "    \n",
    "    for i in range(samples):\n",
    "        inputs.append(data.pandaData[start+i])        \n",
    "        tempLabel = np.zeros_like(data.pandaLabel[i])\n",
    "        tempIndex = data.pandaLabel[i].argmax()\n",
    "        tempLabel[(tempIndex+100) % 1000] = 1\n",
    "        targets.append((tempLabel))\n",
    "        sources.append(tempIndex)\n",
    "\n",
    "    for i in range(samples):\n",
    "        inputs.append(data.cabData[start+i])        \n",
    "        tempLabel = np.zeros_like(data.cabLabel[i])\n",
    "        tempIndex = data.cabLabel[i].argmax()\n",
    "        tempLabel[(tempIndex+100) % 1000] = 1\n",
    "        targets.append((tempLabel))\n",
    "        sources.append(tempIndex)\n",
    "        \n",
    "    for i in range(samples):\n",
    "        inputs.append(data.pineappleData[start+i])        \n",
    "        tempLabel = np.zeros_like(data.pineappleLabel[i])\n",
    "        tempIndex = data.pineappleLabel[i].argmax()\n",
    "        tempLabel[(tempIndex+100) % 1000] = 1\n",
    "        targets.append((tempLabel))\n",
    "        sources.append(tempIndex)\n",
    "        \n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "    return inputs, sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(image_data):\n",
    "    image_data = np.reshape(image_data,(299,299,3))\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2[image_data2<-0.5]=-0.5\n",
    "    image_data2[image_data2>0.5]=0.5\n",
    "    return image_data2\n",
    "\n",
    "def seperateScalarQuantizationLeft(image_data, step):\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2 = (image_data2+0.5)*255\n",
    "    image_data2 = np.floor(image_data2/step)\n",
    "    image_data2 = image_data2*step\n",
    "    image_data2 = image_data2/255-0.5\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter1(image_data):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(299):\n",
    "        for v in range(299):\n",
    "            if (z<2) or (z>296) or (v<2) or (v>296):\n",
    "                avg_r=image_data[z][v][0]\n",
    "                avg_g=image_data[z][v][1]\n",
    "                avg_b=image_data[z][v][2]\n",
    "            else:\n",
    "                avg_r=(image_data[z-2][v][0]+image_data[z-1][v][0]+image_data[z][v-2][0]+image_data[z][v-1][0]+image_data[z][v][0]+\n",
    "                       image_data[z][v+1][0]+image_data[z][v+2][0]+image_data[z+1][v][0]+image_data[z+2][v][0])/9.0\n",
    "                avg_g=(image_data[z-2][v][1]+image_data[z-1][v][1]+image_data[z][v-2][1]+image_data[z][v-1][1]+image_data[z][v][1]+\n",
    "                       image_data[z][v+1][1]+image_data[z][v+2][1]+image_data[z+1][v][1]+image_data[z+2][v][1])/9.0\n",
    "                avg_b=(image_data[z-2][v][2]+image_data[z-1][v][2]+image_data[z][v-2][2]+image_data[z][v-1][2]+image_data[z][v][2]+\n",
    "                       image_data[z][v+1][2]+image_data[z][v+2][2]+image_data[z+1][v][2]+image_data[z+2][v][2])/9.0\n",
    "            image_data2[z][v]=avg_r\n",
    "    return image_data2\n",
    "\n",
    "def chooseCloserFilter(original_data,filter_data1,filter_data2):\n",
    "    result_data=np.zeros_like(original_data)\n",
    "    for j in range(299):\n",
    "        for k in range(299):\n",
    "            for i in range(3):\n",
    "                a=abs(filter_data1[j][k][i]-original_data[j][k][i])\n",
    "                b=abs(filter_data2[j][k][i]-original_data[j][k][i])\n",
    "                if(a<b):\n",
    "                    result_data[j][k][i]=filter_data1[j][k][i]\n",
    "                else:\n",
    "                    result_data[j][k][i]=filter_data2[j][k][i]\n",
    "    return result_data\n",
    "\n",
    "def expandImage(image_data):\n",
    "    image_data2 = (0.5+np.reshape(image_data,((299,299,3))))*255\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter55forInceptionV3(image_data):\n",
    "    image_data = image_data.astype(np.float32)\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(299):\n",
    "        for v in range(299):\n",
    "                if (z<2) or (z>296) or (v<2) or (v>296):\n",
    "                    avg_r=image_data[z][v][0]\n",
    "                    avg_g=image_data[z][v][1]\n",
    "                    avg_b=image_data[z][v][2]\n",
    "                else:\n",
    "                    avg_r=((image_data[z-2][v-2][0]+image_data[z-2][v-1][0]+image_data[z-2][v][0]+image_data[z-2][v+1][0]+image_data[z-2][v+2][0]\n",
    "                           +image_data[z-1][v-2][0]+image_data[z-1][v-1][0]+image_data[z-1][v][0]+image_data[z-1][v+1][0]+image_data[z-1][v+2][0]\n",
    "                           +image_data[z][v-2][0]+image_data[z][v-1][0]+image_data[z][v][0]+image_data[z][v+1][0]+image_data[z][v+2][0]\n",
    "                           +image_data[z+1][v-2][0]+image_data[z+1][v-1][0]+image_data[z+1][v][0]+image_data[z+1][v+1][0]+image_data[z+1][v+2][0]\n",
    "                           +image_data[z+2][v-2][0]+image_data[z+2][v-1][0]+image_data[z+2][v][0]+image_data[z+2][v+1][0]+image_data[z+2][v+2][0])/25.0)\n",
    "                    avg_g=((image_data[z-2][v-2][1]+image_data[z-2][v-1][1]+image_data[z-2][v][1]+image_data[z-2][v+1][1]+image_data[z-2][v+2][1]\n",
    "                           +image_data[z-1][v-2][1]+image_data[z-1][v-1][1]+image_data[z-1][v][1]+image_data[z-1][v+1][1]+image_data[z-1][v+2][1]\n",
    "                           +image_data[z][v-2][1]+image_data[z][v-1][1]+image_data[z][v][1]+image_data[z][v+1][1]+image_data[z][v+2][1]\n",
    "                           +image_data[z+1][v-2][1]+image_data[z+1][v-1][1]+image_data[z+1][v][1]+image_data[z+1][v+1][1]+image_data[z+1][v+2][1]\n",
    "                           +image_data[z+2][v-2][1]+image_data[z+2][v-1][1]+image_data[z+2][v][1]+image_data[z+2][v+1][1]+image_data[z+2][v+2][1])/25.0)\n",
    "                    avg_b=((image_data[z-2][v-2][2]+image_data[z-2][v-1][2]+image_data[z-2][v][2]+image_data[z-2][v+1][2]+image_data[z-2][v+2][2]\n",
    "                           +image_data[z-1][v-2][2]+image_data[z-1][v-1][2]+image_data[z-1][v][2]+image_data[z-1][v+1][2]+image_data[z-1][v+2][2]\n",
    "                           +image_data[z][v-2][2]+image_data[z][v-1][2]+image_data[z][v][2]+image_data[z][v+1][2]+image_data[z][v+2][2]\n",
    "                           +image_data[z+1][v-2][2]+image_data[z+1][v-1][2]+image_data[z+1][v][2]+image_data[z+1][v+1][2]+image_data[z+1][v+2][2]\n",
    "                           +image_data[z+2][v-2][2]+image_data[z+2][v-1][2]+image_data[z+2][v][2]+image_data[z+2][v+1][2]+image_data[z+2][v+2][2])/25.0)\n",
    "                image_data2[z][v][0]=avg_r\n",
    "                image_data2[z][v][1]=avg_g\n",
    "                image_data2[z][v][2]=avg_b\n",
    "    return image_data2\n",
    "\n",
    "def image2DEntropy55(image_data):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    image_data2=meanFilter55forInceptionV3(image_data)\n",
    "\n",
    "    B_entropy=0\n",
    "    G_entropy=0\n",
    "    R_entropy=0\n",
    "    B_num = [([0] * 256) for x in range(256)]\n",
    "    G_num = [([0] * 256) for x in range(256)]\n",
    "    R_num = [([0] * 256) for x in range(256)]\n",
    "    pmf_B = [([0] * 256) for x in range(256)]\n",
    "    pmf_G = [([0] * 256) for x in range(256)]\n",
    "    pmf_R = [([0] * 256) for x in range(256)]\n",
    "    for i in range(299):\n",
    "        for j in range(299):\n",
    "            B_val=int (image_data[i][j][0])\n",
    "            G_val=int (image_data[i][j][1])\n",
    "            R_val=int (image_data[i][j][2])\n",
    "            B_avg=int (image_data2[i][j][0])\n",
    "            G_avg=int (image_data2[i][j][1])\n",
    "            R_avg=int (image_data2[i][j][2])\n",
    "            B_num[B_val][B_avg]=B_num[B_val][B_avg]+1\n",
    "            G_num[G_val][G_avg]=G_num[G_val][G_avg]+1\n",
    "            R_num[R_val][R_avg]=R_num[R_val][R_avg]+1\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            pmf_B[k][m]=B_num[k][m]/(299.0*299.0)\n",
    "            pmf_G[k][m]=G_num[k][m]/(299.0*299.0)\n",
    "            pmf_R[k][m]=R_num[k][m]/(299.0*299.0)\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            if (pmf_B[k][m]!=0):\n",
    "                B_entropy=B_entropy+pmf_B[k][m]*math.log10(pmf_B[k][m])/math.log10(2)\n",
    "            if (pmf_G[k][m]!=0):\n",
    "                G_entropy=G_entropy+pmf_G[k][m]*math.log10(pmf_G[k][m])/math.log10(2)\n",
    "            if (pmf_R[k][m]!=0):\n",
    "                R_entropy=R_entropy+pmf_R[k][m]*math.log10(pmf_R[k][m])/math.log10(2)\n",
    "    B_entropy=-B_entropy\n",
    "    G_entropy=-G_entropy\n",
    "    R_entropy=-R_entropy\n",
    "    entropy=(B_entropy+G_entropy+R_entropy)/3\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with tf.Session() as sess:\n",
    "        data, model =  ImageNet(), InceptionModel(sess)\n",
    "        img = tf.placeholder(tf.uint8, (299,299,3))\n",
    "        softmax_tensor = tf.import_graph_def(\n",
    "             sess.graph.as_graph_def(),\n",
    "             input_map={'DecodeJpeg:0': tf.reshape(img,((299,299,3)))},\n",
    "             return_elements=['softmax/logits:0'])\n",
    "        \n",
    "        attack = CarliniLi(sess, model, max_iterations=1000)\n",
    "\n",
    "        inputs, sources, targets = my_generate_data2(data, samples=30, start=0)\n",
    "        \n",
    "        original_classified_wrong_number = 0\n",
    "        disturbed_failure_number = 0\n",
    "        test_number = 0\n",
    "        TTP = 0\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "                \n",
    "        advGenTimeSum = 0\n",
    "        oriClassifyTimeSum = 0\n",
    "        advClassifyTimeSum = 0\n",
    "        oriFilteredTimeSum = 0\n",
    "        advFilteredTimeSum = 0\n",
    "\n",
    "        for i in range(len(targets)):\n",
    "            print(i)\n",
    "            \n",
    "            inputIm = inputs[i:(i+1)]\n",
    "            target = targets[i:(i+1)]\n",
    "            \n",
    "            oriCorrectLabel = sources[i]            \n",
    "            \n",
    "            octStart = time.time()\n",
    "            oriPredicatedLabel = model.my_predict(inputIm, img, softmax_tensor)\n",
    "            octEnd = time.time()\n",
    "            \n",
    "            if oriPredicatedLabel != oriCorrectLabel:\n",
    "                print('prediction Error!')\n",
    "                original_classified_wrong_number+=1\n",
    "                continue\n",
    "            \n",
    "            attackStart = time.time()\n",
    "            adv = attack.attack(inputIm,target)\n",
    "            attackEnd = time.time()\n",
    "            \n",
    "            adv = normalization(adv)\n",
    "            adv = np.reshape(adv, inputIm.shape)\n",
    "            actStart = time.time()\n",
    "            advPredicatedLabel = model.my_predict(adv, img, softmax_tensor)\n",
    "            actEnd = time.time()\n",
    "            \n",
    "            if advPredicatedLabel == oriCorrectLabel:\n",
    "                print('Attack Failure!')\n",
    "                disturbed_failure_number+=1\n",
    "                continue\n",
    "            \n",
    "            test_number+=1\n",
    "            \n",
    "            advGenTime = attackEnd-attackStart\n",
    "            oriClassifyTime = octEnd-octStart\n",
    "            advClassifyTime = actEnd-actStart\n",
    "        \n",
    "            tempInput = np.reshape(inputIm,(299,299,3))\n",
    "            tempAdv = np.reshape(adv,(299,299,3))\n",
    "\n",
    "            ofctStart = time.time()\n",
    "            inputForEntropy = expandImage(tempInput)\n",
    "            oriEntropy = image2DEntropy55(inputForEntropy)\n",
    "            oriEntropyStr = 'oriEntropy = %f' % (oriEntropy)\n",
    "            print(oriEntropyStr)\n",
    "            if oriEntropy < 8.5:\n",
    "                inputFinal = seperateScalarQuantizationLeft(tempInput,128)\n",
    "            elif oriEntropy < 9.5:\n",
    "                inputFinal = seperateScalarQuantizationLeft(tempInput, 64)\n",
    "            else:\n",
    "                inputAfterQ = seperateScalarQuantizationLeft(tempInput,50)\n",
    "                inputAfterQandF = meanFilter1(inputAfterQ)\n",
    "                inputFinal = chooseCloserFilter(tempInput, inputAfterQ, inputAfterQandF)\n",
    "            oriFilteredPredicatedLabel = model.my_predict(inputFinal, img, softmax_tensor)\n",
    "            ofctEnd = time.time()\n",
    "\n",
    "            afctStart = time.time()\n",
    "            advForEntropy = expandImage(tempAdv)\n",
    "            advEntropy = image2DEntropy55(advForEntropy)\n",
    "            advEntropyStr = 'advEntropy = %f' % (advEntropy)\n",
    "            print(advEntropyStr)\n",
    "            if advEntropy < 8.5:\n",
    "                advFinal = seperateScalarQuantizationLeft(tempAdv, 128)\n",
    "            elif advEntropy < 9.5:\n",
    "                advFinal = seperateScalarQuantizationLeft(tempAdv, 64)\n",
    "            else:\n",
    "                advAfterQ = seperateScalarQuantizationLeft(tempAdv, 50)\n",
    "                advAfterQandF = meanFilter1(advAfterQ)\n",
    "                advFinal = chooseCloserFilter(tempAdv, advAfterQ,advAfterQandF)\n",
    "            advFilteredPredicatedLabel = model.my_predict(advFinal, img, softmax_tensor)\n",
    "            afctEnd = time.time()\n",
    "\n",
    "            oriFilteredClassifyTime=(ofctEnd-ofctStart)\n",
    "            advFilterClassifyTime=(afctEnd-afctStart)\n",
    "            if advPredicatedLabel != advFilteredPredicatedLabel:\n",
    "                TP+=1\n",
    "                if advFilteredPredicatedLabel == oriCorrectLabel:\n",
    "                    TTP+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "            if oriPredicatedLabel != oriFilteredPredicatedLabel:\n",
    "                FP+=1\n",
    "            \n",
    "            advGenTimeSum+=advGenTime\n",
    "            oriClassifyTimeSum+=oriClassifyTime\n",
    "            advClassifyTimeSum+=advClassifyTime\n",
    "            oriFilteredTimeSum+=oriFilteredClassifyTime\n",
    "            advFilteredTimeSum+=advFilterClassifyTime\n",
    "            \n",
    "            timeStr = \"%f-%f-%f-%f-%f\" % (advGenTimeSum,oriClassifyTimeSum,advClassifyTimeSum,oriFilteredTimeSum,advFilteredTimeSum)\n",
    "            labelStr = '%d-%d-%d-%d' % (oriPredicatedLabel, oriFilteredPredicatedLabel, advPredicatedLabel, advFilteredPredicatedLabel)\n",
    "            statisticStr = '%d-%d-%d: TTP = %d, TP = %d, FN = %d, FP = %d' % (test_number, original_classified_wrong_number, disturbed_failure_number, TTP, TP, FN, FP)\n",
    "            print(timeStr)\n",
    "            print(labelStr)\n",
    "            print(statisticStr)\n",
    "            \n",
    "        Recall = TP/(TP+FN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        starStr = '********************************************************'\n",
    "        recallStr = 'Recall = %.4f' % (Recall)\n",
    "        precisionStr = 'Precision = %.4f' % (Precision)\n",
    "        print(starStr)\n",
    "        print(recallStr)\n",
    "        print(precisionStr)\n",
    "        print(starStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
