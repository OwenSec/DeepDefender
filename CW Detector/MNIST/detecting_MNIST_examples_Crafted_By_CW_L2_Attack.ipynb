{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "home_root = '~/' #change it to your own home path\n",
    "nn_robust_attack_root = '~/nn_robust_attacks/' #change it to where you put the 'nn_robust_attacks' directory\n",
    "import sys\n",
    "sys.path.insert(0,home_root)\n",
    "sys.path.insert(0,nn_robust_attack_root) \n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from setup_mnist import MNIST, MNISTModel\n",
    "from l2_attack import CarliniL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(data, samples, targeted=True, start=0, inception=False):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(samples):\n",
    "        if targeted:\n",
    "            if inception:\n",
    "                seq = random.sample(range(1,1001), 10)\n",
    "            else:\n",
    "                seq = range(data.test_labels.shape[1])\n",
    "\n",
    "            for j in seq:\n",
    "                if (j == np.argmax(data.test_labels[start+i])) and (inception == False):\n",
    "                    continue\n",
    "                inputs.append(data.test_data[start+i])\n",
    "                targets.append(np.eye(data.test_labels.shape[1])[j])\n",
    "        else:\n",
    "            inputs.append(data.test_data[start+i])\n",
    "            tempLabel = np.zeros_like(data.test_labels[i])\n",
    "            tempIndex = data.test_labels[i].argmax()\n",
    "            tempLabel[(tempIndex+1) % 10] = 1\n",
    "            targets.append(tempLabel)\n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "    return inputs, targets\n",
    "\n",
    "def mnistPredicate(img, model):\n",
    "    imgTobePre = np.reshape(img, (1,28,28,1))\n",
    "    preList = np.squeeze(model.model.predict(imgTobePre))\n",
    "    return preList.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(image_data):\n",
    "    image_data = np.reshape(image_data,(28,28))\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2[image_data2 < -0.5] = -0.5\n",
    "    image_data2[image_data2 > 0.5] = 0.5\n",
    "    return image_data2\n",
    "\n",
    "def seperateScalarQuantizationLeft(image_data, step): #for scalar quantization\n",
    "    image_data2=np.array(image_data)\n",
    "    image_data2 = (image_data2+0.5)*255\n",
    "    image_data2 = np.floor(image_data2/step)\n",
    "    image_data2 = image_data2*step\n",
    "    image_data2 = image_data2/255-0.5\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter1(image_data): #for smoothing spatial filter\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(28):\n",
    "        for v in range(28):\n",
    "            if (z<2) or (z>25) or (v<2) or (v>25):\n",
    "                avg_r=image_data[z][v]\n",
    "            else:\n",
    "                avg_r=(image_data[z-2][v]+image_data[z-1][v]+image_data[z][v-2]+image_data[z][v-1]+\n",
    "                       image_data[z][v]+image_data[z][v+1]+image_data[z][v+2]+image_data[z+1][v]+image_data[z+2][v])/9.0\n",
    "            image_data2[z][v]=avg_r\n",
    "    return image_data2\n",
    "\n",
    "def chooseCloserFilter(original_data,filter_data1,filter_data2): #detection filter\n",
    "    result_data=np.zeros_like(original_data)\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            a=abs(filter_data1[j][k]-original_data[j][k])\n",
    "            b=abs(filter_data2[j][k]-original_data[j][k])\n",
    "            if(a<b):\n",
    "                result_data[j][k]=filter_data1[j][k]\n",
    "            else:\n",
    "                result_data[j][k]=filter_data2[j][k]\n",
    "    return result_data\n",
    "\n",
    "def expandImage(image_data):\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2 = (image_data2+0.5)*255\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter55forMnist(image_data):\n",
    "    image_data = image_data.astype(np.float32)\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(28):\n",
    "        for v in range(28):\n",
    "                if (z<2) or (z>25) or (v<2) or (v>25):\n",
    "                    avg_r=image_data[z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[z-2][v-2]+image_data[z-2][v-1]+image_data[z-2][v]+image_data[z-2][v+1]+image_data[z-2][v+2]+\n",
    "                           image_data[z-1][v-2]+image_data[z-1][v-1]+image_data[z-1][v]+image_data[z-1][v+1]+image_data[z-1][v+2]+\n",
    "                           image_data[z][v-2]+image_data[z][v-1]+image_data[z][v]+image_data[z][v+1]+image_data[z][v+2]+\n",
    "                           image_data[z+1][v-2]+image_data[z+1][v-1]+image_data[z+1][v]+image_data[z+1][v+1]+image_data[z+1][v+2]+\n",
    "                           image_data[z+2][v-2]+image_data[z+2][v-1]+image_data[z+2][v]+image_data[z+2][v+1]+image_data[z+2][v+2])/25.0\n",
    "                image_data2[z][v]=avg_r\n",
    "    return image_data2\n",
    "\n",
    "\n",
    "def image2DEntropy55_28(image_data): #computing entropy for a 28*28 MNIST image\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    image_data2=meanFilter55forMnist(image_data)\n",
    "    B_entropy=0\n",
    "    B_num = [([0] * 256) for x in range(256)]\n",
    "    pmf_B = [([0] * 256) for x in range(256)]\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            B_val=int (image_data[i][j])\n",
    "            B_avg=int (image_data2[i][j])\n",
    "            B_num[B_val][B_avg]=B_num[B_val][B_avg]+1\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            pmf_B[k][m]=B_num[k][m]/(28.0*28.0)\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            if (pmf_B[k][m]!=0):\n",
    "                B_entropy=B_entropy+pmf_B[k][m]*math.log10(pmf_B[k][m])/math.log10(2)\n",
    "    B_entropy=-B_entropy\n",
    "    return B_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with tf.Session() as sess:\n",
    "        modelPath = '%smodels/mnist' % (nn_robust_attack_root)\n",
    "        data, model =  MNIST(), MNISTModel(modelPath, sess)\n",
    "        \n",
    "        attack = CarliniL2(sess, model, batch_size=1, max_iterations=1000, confidence=0)\n",
    "\n",
    "        inputs, targets = generate_data(data, samples=1000, targeted=False, start=0, inception=False)\n",
    "        \n",
    "        original_classified_wrong_number = 0 #number of benign samples that are misclassified \n",
    "        disturbed_failure_number = 0 #number of samples that failed to craft corresponding adversarial samples\n",
    "        test_number = 0 #number of adversarial samples that we generate\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        \n",
    "        advGenTimeSum = 0 #total time for successfully crafting adversarial examples\n",
    "        oriClassifyTimeSum = 0 #total time for classify the benign samples\n",
    "        advClassifyTimeSum = 0 #total time for classify the adversarial samples\n",
    "        oriFilteredTimeSum = 0 #totoal time that our detection filter takes to detect all the benign samples\n",
    "        advFilteredTimeSum = 0 #total time that our detection filter takes to detect all the adversarial samples\n",
    "\n",
    "        for i in range(len(targets)):\n",
    "            print(i)\n",
    "            \n",
    "            inputIm = inputs[i:(i+1)]\n",
    "            target = targets[i:(i+1)]\n",
    "            \n",
    "            oriCorrectLabel = data.test_labels[i].argmax()            \n",
    "            \n",
    "            octStart = time.time()\n",
    "            oriPredicatedLabel = mnistPredicate(inputIm, model)\n",
    "            octEnd = time.time()\n",
    "            \n",
    "            if oriPredicatedLabel != oriCorrectLabel:\n",
    "                original_classified_wrong_number+=1\n",
    "                continue\n",
    "            \n",
    "            attackStart = time.time()\n",
    "            adv = attack.attack(inputIm,target)\n",
    "            attackEnd = time.time()\n",
    "            \n",
    "            adv = normalization(adv)\n",
    "            adv = np.reshape(adv, inputIm.shape)\n",
    "            actStart = time.time()\n",
    "            advPredicatedLabel = mnistPredicate(adv, model)\n",
    "            actEnd = time.time()\n",
    "            \n",
    "            if advPredicatedLabel == oriCorrectLabel:\n",
    "                disturbed_failure_number+=1\n",
    "                continue\n",
    "            \n",
    "            test_number+=1\n",
    "            \n",
    "            advGenTime = attackEnd-attackStart\n",
    "            oriClassifyTime = octEnd-octStart\n",
    "            advClassifyTime = actEnd-actStart\n",
    "        \n",
    "            tempInput = np.reshape(inputIm,(28,28))\n",
    "            tempAdv = np.reshape(adv,(28,28))\n",
    "\n",
    "            ofctStart = time.time()\n",
    "            inputForEntropy = expandImage(tempInput)\n",
    "            oriEntropy = image2DEntropy55_28(inputForEntropy)\n",
    "            print('oriEntropy = %f' % (oriEntropy))\n",
    "            if oriEntropy < 8.5:\n",
    "                inputFinal = seperateScalarQuantizationLeft(tempInput,128)\n",
    "            elif oriEntropy < 9.5:\n",
    "                inputFinal = seperateScalarQuantizationLeft(tempInput, 64)\n",
    "            else:\n",
    "                inputAfterQ = seperateScalarQuantizationLeft(tempInput,50)\n",
    "                inputAfterQandF = meanFilter1(inputAfterQ)\n",
    "                inputFinal = chooseCloserFilter(tempInput, inputAfterQ, inputAfterQandF)\n",
    "            oriFilteredPredicatedLabel = mnistPredicate(inputFinal, model)\n",
    "            ofctEnd = time.time()\n",
    "\n",
    "            afctStart = time.time()\n",
    "            advForEntropy = expandImage(tempAdv)\n",
    "            advEntropy = image2DEntropy55_28(advForEntropy)\n",
    "            print('advEntropy = %f' % (advEntropy))\n",
    "            if advEntropy < 8.5:\n",
    "                advFinal = seperateScalarQuantizationLeft(tempAdv, 128)\n",
    "            elif advEntropy < 9.5:\n",
    "                advFinal = seperateScalarQuantizationLeft(tempAdv, 64)\n",
    "            else:\n",
    "                advAfterQ = seperateScalarQuantizationLeft(tempAdv, 50)\n",
    "                advAfterQandF = meanFilter1(advAfterQ)\n",
    "                advFinal = chooseCloserFilter(tempAdv, advAfterQ,advAfterQandF)\n",
    "            advFilteredPredicatedLabel = mnistPredicate(advFinal, model)\n",
    "            afctEnd = time.time()\n",
    "\n",
    "            oriFilteredClassifyTime=(ofctEnd-ofctStart)\n",
    "            advFilterClassifyTime=(afctEnd-afctStart)\n",
    "            if advPredicatedLabel != advFilteredPredicatedLabel:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "            if oriPredicatedLabel != oriFilteredPredicatedLabel:\n",
    "                FP+=1\n",
    "            \n",
    "            advGenTimeSum+=advGenTime\n",
    "            oriClassifyTimeSum+=oriClassifyTime\n",
    "            advClassifyTimeSum+=advClassifyTime\n",
    "            oriFilteredTimeSum+=oriFilteredClassifyTime\n",
    "            advFilteredTimeSum+=advFilterClassifyTime\n",
    "            \n",
    "            timeStr = \"%f-%f-%f-%f-%f\" % (advGenTimeSum,oriClassifyTimeSum,advClassifyTimeSum,oriFilteredTimeSum,advFilteredTimeSum)\n",
    "            labelStr = '%d-%d-%d-%d' % (oriPredicatedLabel, oriFilteredPredicatedLabel, advPredicatedLabel, advFilteredPredicatedLabel)\n",
    "            statisticStr = '%d-%d-%d: TP = %d, FN = %d, FP = %d' % (test_number, original_classified_wrong_number, disturbed_failure_number, TP, FN, FP)\n",
    "            print(timeStr)\n",
    "            print(labelStr)\n",
    "            print(statisticStr)\n",
    "            \n",
    "        Recall = TP/(TP+FN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        starStr = '********************************************************'\n",
    "        recallStr = 'Recall = %.4f' % (Recall)\n",
    "        precisionStr = 'Precision = %.4f' % (Precision)\n",
    "        print(starStr)\n",
    "        print(recallStr)\n",
    "        print(precisionStr)\n",
    "        print(starStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
