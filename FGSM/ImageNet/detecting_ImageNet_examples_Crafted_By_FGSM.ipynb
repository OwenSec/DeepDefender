{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.mlab as mlab  \n",
    "import scipy.integrate as integrate\n",
    "from PIL import Image\n",
    "from scipy import fft\n",
    "from scipy import misc\n",
    "from skimage import transform\n",
    "import shutil\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.mpl_style', 'default')\n",
    "%matplotlib inline\n",
    "\n",
    "caffe_root = '~/caffe/'\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    BATCH_SIZE = 1\n",
    "    model_def = caffe_root + 'models/bvlc_googlenet/deploy.prototxt.test'\n",
    "    net_weights =caffe_root + '/models/bvlc_googlenet/bvlc_googlenet.caffemodel'\n",
    "    net = caffe.Net(model_def, net_weights, caffe.TEST)\n",
    "    # change batch size to 1 for faster processing\n",
    "    # this just means that we're only processing one image at a time instead of like 50\n",
    "    shape = list(net.blobs['data'].data.shape)\n",
    "    shape[0] = BATCH_SIZE\n",
    "    net.blobs['data'].reshape(*shape)\n",
    "    net.blobs['prob'].reshape(BATCH_SIZE, )\n",
    "    net.reshape()\n",
    "    return net\n",
    "\n",
    "def compute_gradient(image, intended_outcome):\n",
    "    predict(image, display_output=False)\n",
    "    # Get an empty set of probabilities\n",
    "    probs = np.zeros_like(net.blobs['prob'].data)\n",
    "    # Set the probability for the outcome to -1\n",
    "    probs[0][intended_outcome] = -1 \n",
    "    # Do backpropagation to calculate the gradient for that outcome\n",
    "    gradient = net.backward(prob=probs)\n",
    "    return gradient['data'].copy()\n",
    "\n",
    "def display(data):\n",
    "    plt.imshow(transformer.deprocess('data', data))\n",
    "    \n",
    "def get_label_name(num):\n",
    "    options = labels[num].split(',')\n",
    "    # remove the tag\n",
    "    options[0] = ' '.join(options[0].split(' ')[1:])\n",
    "    return ','.join(options[:2])\n",
    "\n",
    "def predict(data, n_preds=6, display_output=True):\n",
    "    net.blobs['data'].data[...] = data\n",
    "    #if display_output:\n",
    "        #display(data)\n",
    "    prob = net.forward()['prob']\n",
    "    probs = prob[0]\n",
    "    prediction = probs.argmax()\n",
    "    top_k = probs.argsort()[::-1]\n",
    "    for pred in top_k[:n_preds]:\n",
    "        percent = round(probs[pred] * 100, 2)\n",
    "        # display it compactly if we're displaying more than the top prediction\n",
    "        pred_formatted = \"%03d\" % pred\n",
    "        if n_preds == 1:\n",
    "            format_string = \"label: {cls} ({label})\\ncertainty: {certainty}%\"\n",
    "        else:\n",
    "            format_string = \"label: {cls} ({label}), certainty: {certainty}%\"\n",
    "        if display_output:\n",
    "            print format_string.format(\n",
    "                cls=pred_formatted, label=get_label_name(pred), certainty=percent)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanFilter(image_data,kernel_size):#mean filter without padding 1/9 or 1/25\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    if (kernel_size==3):\n",
    "        for z in range(224):\n",
    "            for v in range(224):\n",
    "                if (z==0) or (z==223) or (v==0) or (v==223):\n",
    "                    avg_r=image_data[0][z][v]\n",
    "                    avg_g=image_data[1][z][v]\n",
    "                    avg_b=image_data[2][z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[0][z-1][v-1]+image_data[0][z-1][v]+image_data[0][z-1][v+1]+image_data[0][z][v-1]+image_data[0][z][v]+image_data[0][z][v+1]+image_data[0][z+1][v-1]+image_data[0][z+1][v]+image_data[0][z+1][v+1])/9.0\n",
    "                    avg_g=(image_data[1][z-1][v-1]+image_data[1][z-1][v]+image_data[1][z-1][v+1]+image_data[1][z][v-1]+image_data[1][z][v]+image_data[1][z][v+1]+image_data[1][z+1][v-1]+image_data[1][z+1][v]+image_data[1][z+1][v+1])/9.0\n",
    "                    avg_b=(image_data[2][z-1][v-1]+image_data[2][z-1][v]+image_data[2][z-1][v+1]+image_data[2][z][v-1]+image_data[2][z][v]+image_data[2][z][v+1]+image_data[2][z+1][v-1]+image_data[2][z+1][v]+image_data[2][z+1][v+1])/9.0\n",
    "                image_data2[0][z][v]=avg_r\n",
    "                image_data2[1][z][v]=avg_g\n",
    "                image_data2[2][z][v]=avg_b\n",
    "    elif (kernel_size==5):\n",
    "        for z in range(224):\n",
    "            for v in range(224):\n",
    "                if (z<2) or (z>221) or (v<2) or (v>221):\n",
    "                    avg_r=image_data[0][z][v]\n",
    "                    avg_g=image_data[1][z][v]\n",
    "                    avg_b=image_data[2][z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[0][z-2][v-2]+image_data[0][z-2][v-1]+image_data[0][z-2][v]+image_data[0][z-2][v+1]+image_data[0][z-2][v+2]+image_data[0][z-1][v-2]+image_data[0][z-1][v-1]+image_data[0][z-1][v]+image_data[0][z-1][v+1]+image_data[0][z-1][v+2]+image_data[0][z][v-2]+image_data[0][z][v-1]+image_data[0][z][v]+image_data[0][z][v+1]+image_data[0][z][v+2]+image_data[0][z+1][v-2]+image_data[0][z+1][v-1]+image_data[0][z+1][v]+image_data[0][z+1][v+1]+image_data[0][z+1][v+2]+image_data[0][z+2][v-2]+image_data[0][z+2][v-1]+image_data[0][z+2][v]+image_data[0][z+2][v+1]+image_data[0][z+2][v+2])/25.0\n",
    "                    avg_g=(image_data[1][z-2][v-2]+image_data[1][z-2][v-1]+image_data[1][z-2][v]+image_data[1][z-2][v+1]+image_data[1][z-2][v+2]+image_data[1][z-1][v-2]+image_data[1][z-1][v-1]+image_data[1][z-1][v]+image_data[1][z-1][v+1]+image_data[1][z-1][v+2]+image_data[1][z][v-2]+image_data[1][z][v-1]+image_data[1][z][v]+image_data[1][z][v+1]+image_data[1][z][v+2]+image_data[1][z+1][v-2]+image_data[1][z+1][v-1]+image_data[1][z+1][v]+image_data[1][z+1][v+1]+image_data[1][z+1][v+2]+image_data[1][z+2][v-2]+image_data[1][z+2][v-1]+image_data[1][z+2][v]+image_data[1][z+2][v+1]+image_data[1][z+2][v+2])/25.0\n",
    "                    avg_b=(image_data[2][z-2][v-2]+image_data[2][z-2][v-1]+image_data[2][z-2][v]+image_data[2][z-2][v+1]+image_data[2][z-2][v+2]+image_data[2][z-1][v-2]+image_data[2][z-1][v-1]+image_data[2][z-1][v]+image_data[2][z-1][v+1]+image_data[2][z-1][v+2]+image_data[2][z][v-2]+image_data[2][z][v-1]+image_data[2][z][v]+image_data[2][z][v+1]+image_data[2][z][v+2]+image_data[2][z+1][v-2]+image_data[2][z+1][v-1]+image_data[2][z+1][v]+image_data[2][z+1][v+1]+image_data[2][z+1][v+2]+image_data[2][z+2][v-2]+image_data[2][z+2][v-1]+image_data[2][z+2][v]+image_data[2][z+2][v+1]+image_data[2][z+2][v+2])/25.0\n",
    "                image_data2[0][z][v]=avg_r\n",
    "                image_data2[1][z][v]=avg_g\n",
    "                image_data2[2][z][v]=avg_b\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter1(image_data,kernel_size):#cross mean filter 1/5 or 1/9\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    if (kernel_size==3):\n",
    "        for z in range(224):\n",
    "            for v in range(224):\n",
    "                if (z==0) or (z==223) or (v==0) or (v==223):\n",
    "                    avg_r=image_data[0][z][v]\n",
    "                    avg_g=image_data[1][z][v]\n",
    "                    avg_b=image_data[2][z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[0][z-1][v]+image_data[0][z][v-1]+image_data[0][z][v]+image_data[0][z][v+1]+image_data[0][z+1][v])/5.0\n",
    "                    avg_g=(image_data[1][z-1][v]+image_data[1][z][v-1]+image_data[1][z][v]+image_data[1][z][v+1]+image_data[1][z+1][v])/5.0\n",
    "                    avg_b=(image_data[2][z-1][v]+image_data[2][z][v-1]+image_data[2][z][v]+image_data[2][z][v+1]+image_data[2][z+1][v])/5.0\n",
    "                image_data2[0][z][v]=avg_r\n",
    "                image_data2[1][z][v]=avg_g\n",
    "                image_data2[2][z][v]=avg_b\n",
    "    elif (kernel_size==5):\n",
    "        for z in range(224):\n",
    "            for v in range(224):\n",
    "                if (z<2) or (z>221) or (v<2) or (v>221):\n",
    "                    avg_r=image_data[0][z][v]\n",
    "                    avg_g=image_data[1][z][v]\n",
    "                    avg_b=image_data[2][z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[0][z-2][v]+image_data[0][z-1][v]+image_data[0][z][v-2]+image_data[0][z][v-1]+image_data[0][z][v]+image_data[0][z][v+1]+image_data[0][z][v+2]+image_data[0][z+1][v]+image_data[0][z+2][v])/9.0\n",
    "                    avg_g=(image_data[1][z-2][v]+image_data[1][z-1][v]+image_data[1][z][v-2]+image_data[1][z][v-1]+image_data[1][z][v]+image_data[1][z][v+1]+image_data[1][z][v+2]+image_data[1][z+1][v]+image_data[1][z+2][v])/9.0\n",
    "                    avg_b=(image_data[2][z-2][v]+image_data[2][z-1][v]+image_data[2][z][v-2]+image_data[2][z][v-1]+image_data[2][z][v]+image_data[2][z][v+1]+image_data[2][z][v+2]+image_data[2][z+1][v]+image_data[2][z+2][v])/9.0\n",
    "                image_data2[0][z][v]=avg_r\n",
    "                image_data2[1][z][v]=avg_g\n",
    "                image_data2[2][z][v]=avg_b\n",
    "    return image_data2\n",
    "\n",
    "def add_matrix(image_data,offset,ratio):\n",
    "    result_data=np.zeros_like(image_data)\n",
    "    for x in range(1):\n",
    "        for y in range(3):\n",
    "            for z in range(224):\n",
    "                for v in range(224):\n",
    "                    result_data[y][z][v]=image_data[y][z][v]+ratio*offset[x][y][z][v]\n",
    "                    if(result_data[y][z][v]<0):\n",
    "                        result_data[y][z][v]=0\n",
    "                    if(result_data[y][z][v]>255):\n",
    "                        result_data[y][z][v]=255\n",
    "    return result_data\n",
    "\n",
    "#Imagenet 2D entropy, mean filter: 5*5 1/25\n",
    "def image2DEntropy55(image_data):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    image_data2=meanFilter(image_data,5)\n",
    "    B_entropy=0\n",
    "    G_entropy=0\n",
    "    R_entropy=0\n",
    "    B_num = [([0] * 256) for x in range(256)]\n",
    "    G_num = [([0] * 256) for x in range(256)]\n",
    "    R_num = [([0] * 256) for x in range(256)]\n",
    "    pmf_B = [([0] * 256) for x in range(256)]\n",
    "    pmf_G = [([0] * 256) for x in range(256)]\n",
    "    pmf_R = [([0] * 256) for x in range(256)]\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            B_val=int (image_data[0][i][j])\n",
    "            G_val=int (image_data[1][i][j])\n",
    "            R_val=int (image_data[2][i][j])\n",
    "            B_avg=int (image_data2[0][i][j])\n",
    "            G_avg=int (image_data2[1][i][j])\n",
    "            R_avg=int (image_data2[2][i][j])\n",
    "            B_num[B_val][B_avg]=B_num[B_val][B_avg]+1\n",
    "            G_num[G_val][G_avg]=G_num[G_val][G_avg]+1\n",
    "            R_num[R_val][R_avg]=R_num[R_val][R_avg]+1\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            pmf_B[k][m]=B_num[k][m]/(224.0*224.0)\n",
    "            pmf_G[k][m]=G_num[k][m]/(224.0*224.0)\n",
    "            pmf_R[k][m]=R_num[k][m]/(224.0*224.0)\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            if (pmf_B[k][m]!=0):\n",
    "                B_entropy=B_entropy+pmf_B[k][m]*math.log10(pmf_B[k][m])/math.log10(2)\n",
    "            if (pmf_G[k][m]!=0):\n",
    "                G_entropy=G_entropy+pmf_G[k][m]*math.log10(pmf_G[k][m])/math.log10(2)\n",
    "            if (pmf_R[k][m]!=0):\n",
    "                R_entropy=R_entropy+pmf_R[k][m]*math.log10(pmf_R[k][m])/math.log10(2)\n",
    "    B_entropy=-B_entropy\n",
    "    G_entropy=-G_entropy\n",
    "    R_entropy=-R_entropy\n",
    "    entropy=(B_entropy+G_entropy+R_entropy)/3\n",
    "    return entropy\n",
    "\n",
    "#RGB各自阶梯量化左值\n",
    "def seperateScalarQuantizationLeft(image_data,step_B,step_G,step_R):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for j in range(224):\n",
    "        for k in range(224):\n",
    "            segment_B=np.floor(image_data[0][j][k]/step_B)\n",
    "            image_data2[0][j][k]=segment_B*step_B\n",
    "            segment_G=np.floor(image_data[1][j][k]/step_G)\n",
    "            image_data2[1][j][k]=segment_G*step_G\n",
    "            segment_R=np.floor(image_data[2][j][k]/step_R)\n",
    "            image_data2[2][j][k]=segment_R*step_R\n",
    "    return image_data2\n",
    "def chooseCloserFilter(original_data,filter_data1,filter_data2):\n",
    "    result_data=np.zeros_like(original_data)\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                a=abs(filter_data1[i][j][k]-original_data[i][j][k])\n",
    "                b=abs(filter_data2[i][j][k]-original_data[i][j][k])\n",
    "                if(a<b):\n",
    "                    result_data[i][j][k]=filter_data1[i][j][k]\n",
    "                else:\n",
    "                    result_data[i][j][k]=filter_data2[i][j][k]\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step is the size of quantization interval,epsilon defines the perturbation(set as 1.0 in [0,255] scale)\n",
    "def DDforFGSMImageNet(rootDir,true_class):\n",
    "    list_dirs = os.walk(rootDir) \n",
    "    Total=0.0\n",
    "    TP=0.0\n",
    "    FP=0.0\n",
    "    FN=0.0    \n",
    "    for root, dirs, files in list_dirs: \n",
    "        for d in dirs: \n",
    "            print os.path.join(root, d)      \n",
    "        for f in files: \n",
    "            original_data=transformer.preprocess('data', caffe.io.load_image(os.path.join(root, f)))\n",
    "            net.blobs['data'].data[...] = original_data\n",
    "            ori_out = net.forward()\n",
    "            pred_class = ori_out['prob'][0].argmax()\n",
    "            grad = compute_gradient(original_data, pred_class)\n",
    "            delta = np.sign(grad)\n",
    "            adversarial_data=add_matrix(original_data,delta,1.0)\n",
    "            net.blobs['data'].data[...] = adversarial_data\n",
    "            adv_out = net.forward()\n",
    "            adv_class = adv_out['prob'][0].argmax()\n",
    "            if (pred_class==true_class) and (adv_class!=true_class):\n",
    "                print os.path.join(root, f) \n",
    "                Total=Total+1\n",
    "                ori_entropy=image2DEntropy55(original_data)\n",
    "                if (ori_entropy<8.50):\n",
    "                    im3=seperateScalarQuantizationLeft(original_data,128,128,128)\n",
    "                elif (ori_entropy<=9.50):\n",
    "                    im3=seperateScalarQuantizationLeft(original_data,64,64,64)\n",
    "                else: #ori_entropy>9.50\n",
    "                    im1=seperateScalarQuantizationLeft(original_data,50,50,50)\n",
    "                    im2=meanFilter1(im1,5)\n",
    "                    im3=chooseCloserFilter(original_data,im1,im2)\n",
    "                net.blobs['data'].data[...] = im3\n",
    "                ori_filtered_out = net.forward()\n",
    "                ori_filtered_class = ori_filtered_out['prob'][0].argmax()\n",
    "                adv_entropy=image2DEntropy55(adversarial_data)\n",
    "                if (adv_entropy<8.50):\n",
    "                    im6=seperateScalarQuantizationLeft(adversarial_data,128,128,128)\n",
    "                elif (adv_entropy<=9.50):\n",
    "                    im6=seperateScalarQuantizationLeft(adversarial_data,64,64,64)\n",
    "                else: #adv_entropy>9.50\n",
    "                    im4=seperateScalarQuantizationLeft(adversarial_data,50,50,50)\n",
    "                    im5=meanFilter1(im4,5)\n",
    "                    im6=chooseCloserFilter(adversarial_data,im4,im5)\n",
    "                net.blobs['data'].data[...] = im6\n",
    "                adv_filtered_out = net.forward()\n",
    "                adv_filtered_class = adv_filtered_out['prob'][0].argmax()\n",
    "                print(\"Ori predicted class is #{}.\".format(pred_class))\n",
    "                probs = predict(original_data, n_preds=2)\n",
    "                print(\"Ori-filter predicted class is #{}.\".format(ori_filtered_class))\n",
    "                probs = predict(im3, n_preds=2)\n",
    "                print(\"Adv predicted class is #{}.\".format(adv_class))\n",
    "                probs = predict(adversarial_data, n_preds=2)\n",
    "                print(\"Adv-filter predicted class is #{}.\".format(adv_filtered_class))\n",
    "                probs = predict(im6, n_preds=2)\n",
    "                if(ori_filtered_class!=true_class):#FP\n",
    "                    FP=FP+1\n",
    "                if (adv_filtered_class!=adv_class):\n",
    "                    TP=TP+1\n",
    "                if (adv_filtered_class==adv_class):\n",
    "                    FN=FN+1\n",
    "                Recall=TP/Total*100.0\n",
    "                if ((TP+FP)!=0):\n",
    "                    Precision=TP/(TP+FP)*100.0\n",
    "                else:\n",
    "                    Precision=0\n",
    "                print(\"Total: \",Total, \"TP: \",TP,\"FP: \",FP,\"FN: \",FN,\"Recall: \",Recall,\"  Precision: \",Precision)\n",
    "    print(\"Overall results: \")\n",
    "    print(\"Total: \",Total, \"TP: \",TP,\"FP: \",FP,\"FN: \",FN)\n",
    "    Recall=TP/Total*100.0\n",
    "    Precision=TP/(TP+FP)*100.0\n",
    "    print (\"Recall: \",Recall)\n",
    "    print (\"Precision: \",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the labels (so we know whether 242 means 'adorable puppy' or 'garbage can')\n",
    "imagenet_labels_filename = caffe_root + '/data/ilsvrc12/synset_words.txt'\n",
    "try:\n",
    "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "except:\n",
    "    !/opt/caffe/data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "    \n",
    "# Set Caffe to CPU mode \n",
    "caffe.set_mode_cpu()\n",
    "#Load CaffeNet for FGSM detection\n",
    "# Load our model! trained by the GOOGLES! <3\n",
    "net = load_model()\n",
    "#transformer \n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_raw_scale('data', 255)  #images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  #channels in BGR order instead of RGB    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test four ImageNet class\n",
    "DDforFGSMImageNet('~/n02391049_ps',340)\n",
    "DDforFGSMImageNet('~/n02510455_ps',388)\n",
    "DDforFGSMImageNet('~/n02930766_ps',468)\n",
    "DDforFGSMImageNet('~/n07753275_ps',953)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
