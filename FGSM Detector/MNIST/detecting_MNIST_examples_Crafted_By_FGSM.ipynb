{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "home_root = '~' #change it to your home path\n",
    "cleverhans_root = '~/cleverhans/' #change it to where you store the 'cleverhans' project\n",
    "import sys\n",
    "sys.path.insert(0,home_root)\n",
    "sys.path.insert(0,cleverhans_root) \n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "from scipy import misc\n",
    "import math\n",
    "import time\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval, model_argmax\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import cnn_model\n",
    "\n",
    "FLAGS = flags.FLAGS #some paths need to be replaced on your own need\n",
    "flags.DEFINE_string('train_dir', 'tmp/', 'Directory storing the saved model.')\n",
    "flags.DEFINE_string('filename', 'mnist.ckpt', 'Filename to save model under.')\n",
    "flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
    "flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "flags.DEFINE_float('learning_rate', 0.1, 'Learning rate for training')\n",
    "flags.DEFINE_integer('img_rows', 28, 'Input row dimension')\n",
    "flags.DEFINE_integer('img_cols', 28, 'Input column dimension')\n",
    "flags.DEFINE_integer('nb_channels', 1, 'Nb of color channels in the input.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(image_data):\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2[image_data2<0] = 0\n",
    "    image_data2[image_data2>1.0] = 1.0\n",
    "    return image_data2\n",
    "\n",
    "def seperateScalarQuantizationLeft(image_data, step):\n",
    "    image_data2 = np.array(image_data)\n",
    "    image_data2 = image_data2*255\n",
    "    image_data2 = np.floor(image_data2/step)\n",
    "    image_data2 = image_data2*step\n",
    "    image_data2 = image_data2/255\n",
    "    return image_data2\n",
    "\n",
    "def meanFilter1(image_data):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(28):\n",
    "        for v in range(28):\n",
    "            if (z<2) or (z>25) or (v<2) or (v>25):\n",
    "                avg_r=image_data[z][v]\n",
    "            else:\n",
    "                avg_r=(image_data[z-2][v]+image_data[z-1][v]+image_data[z][v-2]+image_data[z][v-1]+image_data[z][v]+\n",
    "                       image_data[z][v+1]+image_data[z][v+2]+image_data[z+1][v]+image_data[z+2][v])/9.0\n",
    "            image_data2[z][v]=avg_r\n",
    "    return image_data2\n",
    "\n",
    "def chooseCloserFilter(original_data,filter_data1,filter_data2):\n",
    "    result_data=np.zeros_like(original_data)\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            a=abs(filter_data1[j][k]-original_data[j][k])\n",
    "            b=abs(filter_data2[j][k]-original_data[j][k])\n",
    "            if(a<b):\n",
    "                result_data[j][k]=filter_data1[j][k]\n",
    "            else:\n",
    "                result_data[j][k]=filter_data2[j][k]\n",
    "    return result_data\n",
    "\n",
    "    \n",
    "def meanFilter55forMnist(image_data):\n",
    "    image_data=image_data.astype(np.float32)\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    for z in range(28):\n",
    "        for v in range(28):\n",
    "                if (z<2) or (z>25) or (v<2) or (v>25):\n",
    "                    avg_r=image_data[z][v]\n",
    "                else:\n",
    "                    avg_r=(image_data[z-2][v-2]+image_data[z-2][v-1]+image_data[z-2][v]+image_data[z-2][v+1]+image_data[z-2][v+2]+\n",
    "                           image_data[z-1][v-2]+image_data[z-1][v-1]+image_data[z-1][v]+image_data[z-1][v+1]+image_data[z-1][v+2]+\n",
    "                           image_data[z][v-2]+image_data[z][v-1]+image_data[z][v]+image_data[z][v+1]+image_data[z][v+2]+\n",
    "                           image_data[z+1][v-2]+image_data[z+1][v-1]+image_data[z+1][v]+image_data[z+1][v+1]+image_data[z+1][v+2]+\n",
    "                           image_data[z+2][v-2]+image_data[z+2][v-1]+image_data[z+2][v]+image_data[z+2][v+1]+image_data[z+2][v+2])/25.0\n",
    "                image_data2[z][v]=avg_r\n",
    "    return image_data2\n",
    "\n",
    "\n",
    "def image2DEntropy55_28(image_data):\n",
    "    image_data2=np.zeros_like(image_data)\n",
    "    image_data2=meanFilter55forMnist(image_data)\n",
    "    B_entropy=0\n",
    "    B_num = [([0] * 256) for x in range(256)]\n",
    "    pmf_B = [([0] * 256) for x in range(256)]\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            B_val=int (image_data[i][j])\n",
    "            B_avg=int (image_data2[i][j])\n",
    "            B_num[B_val][B_avg]=B_num[B_val][B_avg]+1\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            pmf_B[k][m]=B_num[k][m]/(28.0*28.0)\n",
    "    for k in range(256):\n",
    "        for m in range(256):\n",
    "            if (pmf_B[k][m]!=0):\n",
    "                B_entropy=B_entropy+pmf_B[k][m]*math.log10(pmf_B[k][m])/math.log10(2)\n",
    "    B_entropy=-B_entropy\n",
    "    return B_entropy\n",
    "\n",
    "def my_model_argmax(sess, x, predictions, samples):\n",
    "    feed_dict = {x: samples}\n",
    "    probabilities = sess.run(predictions, feed_dict)\n",
    "    if samples.shape[0] == 1:\n",
    "        return np.argmax(probabilities)\n",
    "    else:\n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    \"\"\"\n",
    "    MNIST cleverhans tutorial\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph() #it is essential for restoring saved model\n",
    "    \n",
    "    keras.layers.core.K.set_learning_phase(0)\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    if not hasattr(backend, \"tf\"):\n",
    "        raise RuntimeError(\"This tutorial requires keras to be configured\"\n",
    "                           \" to use the TensorFlow backend.\")\n",
    "\n",
    "    # Image dimensions ordering should follow the Theano convention\n",
    "    if keras.backend.image_dim_ordering() != 'tf':\n",
    "        keras.backend.set_image_dim_ordering('tf')\n",
    "        print(\"INFO: '~/.keras/keras.json' sets 'image_dim_ordering' to \"\n",
    "              \"'th', temporarily setting to 'tf'\")\n",
    "\n",
    "    # Create TF session and set as Keras backend session\n",
    "    sess = tf.Session()\n",
    "    keras.backend.set_session(sess)\n",
    "\n",
    "    # Get MNIST test data\n",
    "    X_train, Y_train, X_test, Y_test = data_mnist()\n",
    "\n",
    "    assert Y_train.shape[1] == 10.\n",
    "    label_smooth = .1\n",
    "    Y_train = Y_train.clip(label_smooth / 9., 1. - label_smooth)\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "    # Define TF model graph\n",
    "    model = cnn_model()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = os.path.join(FLAGS.train_dir, FLAGS.filename)\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        train_params = {\n",
    "            'nb_epochs': FLAGS.nb_epochs,\n",
    "            'batch_size': FLAGS.batch_size,\n",
    "            'learning_rate': FLAGS.learning_rate\n",
    "        }\n",
    "        model_train(sess, x, y, predictions, X_train, Y_train,\n",
    "                args=train_params)\n",
    "        saver.save(sess, save_path)\n",
    "\n",
    "    advGenTimeStart = time.time()\n",
    "    fgsm = FastGradientMethod(model, sess=sess)\n",
    "    fgsm_params = {'eps': 0.1}\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    adv_x = sess.run(adv_x, feed_dict={x: X_test[0:10000]})\n",
    "    advGenTimeEnd = time.time()\n",
    "    advGenTime = advGenTimeEnd-advGenTimeStart\n",
    "\n",
    "    original_classified_wrong_number = 0\n",
    "    disturbed_failure_number = 0\n",
    "    test_number = 0\n",
    "    TTP = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    for i in range(len(adv_x)):\n",
    "        current_class = int(np.argmax(Y_test[i]))\n",
    "\n",
    "        oriPreTimeStart = time.time()\n",
    "        currentXLabel = model_argmax(sess,x,predictions,X_test[i:(i+1)])\n",
    "        currentXProbList = my_model_argmax(sess,x,predictions,X_test[i:(i+1)])\n",
    "        oriPreTimeEnd = time.time()\n",
    "        oriPreTime = oriPreTimeEnd-oriPreTimeStart\n",
    "        if currentXLabel != current_class:\n",
    "            original_classified_wrong_number+=1\n",
    "            continue\n",
    "        \n",
    "        advPreTimeStart = time.time()\n",
    "        currentAdvXBeforeNormalization = np.reshape(adv_x[i:(i+1)], (FLAGS.img_rows,FLAGS.img_cols))\n",
    "        currentAdvXAfterNormalization = normalization(currentAdvXBeforeNormalization)\n",
    "        currentAdvXAfterNormalization = np.reshape(currentAdvXAfterNormalization,adv_x[i:(i+1)].shape)\n",
    "        currentAdvXLabel = model_argmax(sess,x,predictions,currentAdvXAfterNormalization)\n",
    "        currentAdvXProbList = my_model_argmax(sess,x,predictions,currentAdvXAfterNormalization)\n",
    "        advPreTimeEnd = time.time()\n",
    "        advPreTime = advPreTimeEnd-advPreTimeStart\n",
    "\n",
    "        if currentAdvXLabel == currentXLabel:\n",
    "            disturbed_failure_number+=1\n",
    "            continue\n",
    "\n",
    "        test_number+=1    \n",
    "        \n",
    "        tempX = np.reshape(X_test[i:(i+1)], (FLAGS.img_rows, FLAGS.img_cols))\n",
    "        test_x = np.array(tempX)\n",
    "        test_x = test_x*255\n",
    "        \n",
    "        oriFilteredPreTimeStart = time.time()\n",
    "        currentX = np.reshape(X_test[i:(i+1)], (FLAGS.img_rows, FLAGS.img_cols))\n",
    "        imageEntropy = image2DEntropy55_28(test_x)\n",
    "        if imageEntropy < 8.5:\n",
    "            current_x_res = seperateScalarQuantizationLeft(currentX, 128)\n",
    "        elif imageEntropy < 9.5:\n",
    "            current_x_res = seperateScalarQuantizationLeft(currentX, 64)\n",
    "        else:\n",
    "            current_x_ASQ = seperateScalarQuantizationLeft(currentX, 50)\n",
    "            current_x_ASQ_AMF = meanFilter1(current_x_ASQ)\n",
    "            current_x_res = chooseCloserFilter(currentX, current_x_ASQ, current_x_ASQ_AMF)\n",
    "        current_x_res = np.reshape(current_x_res, X_test[i:(i+1)].shape)\n",
    "        current_x_res_label = model_argmax(sess,x,predictions,current_x_res)\n",
    "\n",
    "        \n",
    "        tempX2 = np.reshape(adv_x[i:(i+1)], (FLAGS.img_rows, FLAGS.img_cols))\n",
    "        test_adv_x = np.array(tempX2)\n",
    "        test_adv_x = normalization(test_adv_x)\n",
    "        test_adv_x = test_adv_x*255\n",
    "\n",
    "        currentAdvX = np.reshape(adv_x[i:(i+1)], (FLAGS.img_rows, FLAGS.img_cols))\n",
    "        currentAdvX = normalization(currentAdvX)\n",
    "        imageEntropy2 = image2DEntropy55_28(test_adv_x)\n",
    "        print('%d: %f------%f' % (i, imageEntropy,imageEntropy2))\n",
    "        if imageEntropy2 < 8.5:\n",
    "            current_adv_x_res = seperateScalarQuantizationLeft(currentAdvX,128)\n",
    "        elif imageEntropy2 < 9.5:\n",
    "            current_adv_x_res = seperateScalarQuantizationLeft(currentAdvX, 64)\n",
    "        else:\n",
    "            current_adv_x_ASQ = seperateScalarQuantizationLeft(currentAdvX, 50)\n",
    "            current_adv_x_ASQ_AMF = meanFilter1(current_adv_x_ASQ)\n",
    "            current_adv_x_res = chooseCloserFilter(currentAdvX, current_adv_x_ASQ, current_adv_x_ASQ_AMF)\n",
    "        current_adv_x_res = np.reshape(current_adv_x_res, X_test[i:(i+1)].shape)\n",
    "        current_adv_x_res_label = model_argmax(sess,x,predictions,current_adv_x_res)\n",
    "            \n",
    "        if current_adv_x_res_label != currentAdvXLabel:\n",
    "            TP+=1\n",
    "            if current_adv_x_res_label == current_class:\n",
    "                TTP+=1\n",
    "        else:\n",
    "            FN+=1\n",
    "        if current_x_res_label != currentXLabel:\n",
    "            FP+=1\n",
    "        str1 = '%d-%d-%d: TP = %d; FN = %d; FP = %d; TTP = %d' % (test_number,original_classified_wrong_number,disturbed_failure_number,TP,FN,FP,TTP)\n",
    "        print(str1)\n",
    "    \n",
    "    Recall = TP/(TP+FN)\n",
    "    Precision = TP/(TP+FP)\n",
    "    tempStarStr = '********************************************************'\n",
    "    recallStr = 'Recall = %.4f' % (Recall)\n",
    "    precisionStr = 'Precision = %.4f' % (Precision)\n",
    "    print(tempStarStr)\n",
    "    print(recallStr)\n",
    "    print(precisionStr)\n",
    "    print(tempStarStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
